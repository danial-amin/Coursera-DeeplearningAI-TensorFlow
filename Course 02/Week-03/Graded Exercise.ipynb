{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 74, 74, 32)   864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 74, 74, 32)   96          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 74, 74, 32)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 72, 72, 32)   9216        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 72, 72, 32)   96          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 72, 72, 32)   0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 72, 72, 64)   18432       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 72, 72, 64)   192         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 72, 72, 64)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 35, 35, 64)   0           activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 35, 35, 80)   240         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 35, 35, 80)   0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 33, 33, 192)  138240      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 33, 33, 192)  576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 33, 33, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 16, 16, 192)  0           activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 16, 16, 64)   192         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 16, 16, 64)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 96)   55296       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 16, 16, 48)   144         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 16, 16, 96)   288         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 16, 16, 48)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 16, 16, 96)   0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 16, 16, 64)   76800       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 16, 16, 96)   82944       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 16, 16, 64)   192         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 16, 16, 64)   192         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 16, 16, 96)   288         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 16, 16, 32)   96          conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 16, 16, 64)   0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 16, 16, 64)   0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 16, 16, 96)   0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 16, 16, 32)   0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_260[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "                                                                 activation_265[0][0]             \n",
      "                                                                 activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 16, 16, 64)   192         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 16, 16, 64)   0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 16, 16, 96)   55296       activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 16, 16, 48)   144         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 16, 16, 96)   288         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 16, 16, 48)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 16, 16, 96)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 16, 16, 64)   76800       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 16, 16, 96)   82944       activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 16, 16, 64)   192         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 16, 16, 64)   192         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 16, 16, 96)   288         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 16, 16, 64)   192         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 16, 16, 64)   0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 16, 16, 64)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 16, 16, 96)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 16, 16, 64)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_267[0][0]             \n",
      "                                                                 activation_269[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 16, 16, 64)   192         conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 16, 16, 64)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 16, 16, 96)   55296       activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 16, 16, 48)   144         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 16, 16, 96)   288         conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 16, 16, 48)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 16, 16, 96)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 16, 16, 64)   76800       activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 16, 16, 96)   82944       activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 16, 16, 64)   192         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 16, 16, 64)   192         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 16, 16, 96)   288         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 16, 16, 64)   192         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 16, 16, 64)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 16, 16, 64)   0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 16, 16, 96)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 16, 16, 64)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_274[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "                                                                 activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 16, 16, 64)   192         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 16, 16, 64)   0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 16, 16, 96)   55296       activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 16, 16, 96)   288         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 16, 16, 96)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 7, 7, 96)     82944       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 7, 7, 384)    1152        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 7, 7, 96)     288         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 7, 7, 384)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 7, 7, 96)     0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_281[0][0]             \n",
      "                                                                 activation_284[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 7, 7, 128)    384         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 128)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 7, 7, 128)    114688      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 7, 7, 128)    384         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 128)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 7, 7, 128)    114688      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 7, 7, 128)    384         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 7, 7, 128)    384         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 128)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 128)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 7, 7, 128)    114688      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 7, 7, 128)    114688      activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 7, 7, 128)    384         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 7, 7, 128)    384         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 128)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 128)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 7, 7, 192)    172032      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 7, 7, 192)    172032      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 7, 7, 192)    576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 7, 7, 192)    576         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 7, 7, 192)    576         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 7, 7, 192)    576         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 7, 7, 192)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 192)    0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 192)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 192)    0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_285[0][0]             \n",
      "                                                                 activation_288[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 7, 7, 160)    480         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 7, 7, 160)    0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 7, 7, 160)    179200      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 7, 7, 160)    480         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 7, 7, 160)    0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 7, 7, 160)    179200      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 7, 7, 160)    480         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 7, 7, 160)    480         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 7, 7, 160)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 7, 7, 160)    0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 7, 7, 160)    179200      activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 7, 7, 160)    179200      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 7, 7, 160)    480         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 7, 7, 160)    480         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 7, 7, 160)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 7, 7, 160)    0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 7, 7, 192)    215040      activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 7, 7, 192)    215040      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 7, 7, 192)    576         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 7, 7, 192)    576         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 7, 7, 192)    576         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 7, 7, 192)    576         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 7, 7, 192)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 7, 7, 192)    0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 7, 7, 192)    0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 7, 7, 192)    0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_295[0][0]             \n",
      "                                                                 activation_298[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 7, 7, 160)    480         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 7, 7, 160)    0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 7, 7, 160)    179200      activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 7, 7, 160)    480         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 7, 7, 160)    0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 7, 7, 160)    179200      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 7, 7, 160)    480         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 7, 7, 160)    480         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 7, 7, 160)    0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 7, 7, 160)    0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 7, 7, 160)    179200      activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 7, 7, 160)    179200      activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 7, 7, 160)    480         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 7, 7, 160)    480         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 7, 7, 160)    0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 7, 7, 160)    0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 7, 7, 192)    215040      activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 7, 7, 192)    215040      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 7, 7, 192)    576         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 7, 7, 192)    576         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 7, 7, 192)    576         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 7, 7, 192)    576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 7, 7, 192)    0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 7, 7, 192)    0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 7, 7, 192)    0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 7, 7, 192)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_305[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "                                                                 activation_313[0][0]             \n",
      "                                                                 activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 7, 7, 192)    576         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 7, 7, 192)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 7, 7, 192)    258048      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 7, 7, 192)    576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 7, 7, 192)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 7, 7, 192)    258048      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 7, 7, 192)    576         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 7, 7, 192)    576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 7, 7, 192)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 7, 7, 192)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 7, 7, 192)    258048      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 7, 7, 192)    258048      activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 7, 7, 192)    576         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 7, 7, 192)    576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 7, 7, 192)    0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 7, 7, 192)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 7, 7, 192)    258048      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 7, 7, 192)    258048      activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 7, 7, 192)    576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 7, 7, 192)    576         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 7, 7, 192)    576         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 7, 7, 192)    576         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 7, 7, 192)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 7, 7, 192)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 7, 7, 192)    0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 7, 7, 192)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_315[0][0]             \n",
      "                                                                 activation_318[0][0]             \n",
      "                                                                 activation_323[0][0]             \n",
      "                                                                 activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 7, 7, 192)    576         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 7, 7, 192)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 7, 7, 192)    258048      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 7, 7, 192)    576         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 7, 7, 192)    0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 7, 7, 192)    258048      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 7, 7, 192)    576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 7, 7, 192)    576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 7, 7, 192)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 7, 7, 192)    0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 3, 3, 320)    552960      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 3, 3, 192)    331776      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 3, 3, 320)    960         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 3, 3, 192)    576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 3, 3, 320)    0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 3, 3, 192)    0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_326[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 3, 3, 448)    1344        conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 3, 3, 448)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 3, 3, 384)    1548288     activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 3, 3, 384)    1152        conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 3, 3, 384)    1152        conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 3, 3, 384)    0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 3, 3, 384)    0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 3, 3, 384)    442368      activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 3, 3, 384)    442368      activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 3, 3, 384)    442368      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 3, 3, 384)    442368      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 3, 3, 384)    1152        conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 3, 3, 384)    1152        conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 3, 3, 384)    1152        conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 3, 3, 384)    1152        conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 3, 3, 320)    960         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 3, 3, 384)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 3, 3, 384)    0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 3, 3, 384)    0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 3, 3, 384)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 3, 3, 192)    576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 3, 3, 320)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_333[0][0]             \n",
      "                                                                 activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_337[0][0]             \n",
      "                                                                 activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 3, 3, 192)    0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_331[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 3, 3, 448)    1344        conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 3, 3, 448)    0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 3, 3, 384)    1548288     activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 3, 3, 384)    1152        conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 3, 3, 384)    1152        conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 3, 3, 384)    0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 3, 3, 384)    0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 3, 3, 384)    442368      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 3, 3, 384)    442368      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 3, 3, 384)    442368      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 3, 3, 384)    442368      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 3, 3, 384)    1152        conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 3, 3, 384)    1152        conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 3, 3, 384)    1152        conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 3, 3, 384)    1152        conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 3, 3, 320)    960         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 3, 3, 384)    0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 3, 3, 384)    0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 3, 3, 384)    0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 3, 3, 384)    0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 3, 3, 192)    576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 3, 3, 320)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_342[0][0]             \n",
      "                                                                 activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_346[0][0]             \n",
      "                                                                 activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 3, 3, 192)    0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_340[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_348[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.97):\n",
    "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 74, 74, 32)   864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 74, 74, 32)   96          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 74, 74, 32)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 72, 72, 32)   9216        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 72, 72, 32)   96          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 72, 72, 32)   0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 72, 72, 64)   18432       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 72, 72, 64)   192         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 72, 72, 64)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 35, 35, 64)   0           activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 35, 35, 80)   240         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 35, 35, 80)   0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 33, 33, 192)  138240      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 33, 33, 192)  576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 33, 33, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 16, 16, 192)  0           activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 16, 16, 64)   192         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 16, 16, 64)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 96)   55296       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 16, 16, 48)   144         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 16, 16, 96)   288         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 16, 16, 48)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 16, 16, 96)   0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 16, 16, 64)   76800       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 16, 16, 96)   82944       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 16, 16, 64)   192         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 16, 16, 64)   192         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 16, 16, 96)   288         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 16, 16, 32)   96          conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 16, 16, 64)   0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 16, 16, 64)   0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 16, 16, 96)   0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 16, 16, 32)   0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_260[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "                                                                 activation_265[0][0]             \n",
      "                                                                 activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 16, 16, 64)   192         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 16, 16, 64)   0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 16, 16, 96)   55296       activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 16, 16, 48)   144         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 16, 16, 96)   288         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 16, 16, 48)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 16, 16, 96)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 16, 16, 64)   76800       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 16, 16, 96)   82944       activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 16, 16, 64)   192         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 16, 16, 64)   192         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 16, 16, 96)   288         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 16, 16, 64)   192         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 16, 16, 64)   0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 16, 16, 64)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 16, 16, 96)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 16, 16, 64)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_267[0][0]             \n",
      "                                                                 activation_269[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 16, 16, 64)   192         conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 16, 16, 64)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 16, 16, 96)   55296       activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 16, 16, 48)   144         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 16, 16, 96)   288         conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 16, 16, 48)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 16, 16, 96)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 16, 16, 64)   76800       activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 16, 16, 96)   82944       activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 16, 16, 64)   192         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 16, 16, 64)   192         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 16, 16, 96)   288         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 16, 16, 64)   192         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 16, 16, 64)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 16, 16, 64)   0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 16, 16, 96)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 16, 16, 64)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_274[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "                                                                 activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 16, 16, 64)   192         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 16, 16, 64)   0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 16, 16, 96)   55296       activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 16, 16, 96)   288         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 16, 16, 96)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 7, 7, 96)     82944       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 7, 7, 384)    1152        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 7, 7, 96)     288         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 7, 7, 384)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 7, 7, 96)     0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_281[0][0]             \n",
      "                                                                 activation_284[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 7, 7, 128)    384         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 128)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 7, 7, 128)    114688      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 7, 7, 128)    384         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 128)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 7, 7, 128)    114688      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 7, 7, 128)    384         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 7, 7, 128)    384         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 128)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 128)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 7, 7, 128)    114688      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 7, 7, 128)    114688      activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 7, 7, 128)    384         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 7, 7, 128)    384         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 128)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 128)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 7, 7, 192)    172032      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 7, 7, 192)    172032      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 7, 7, 192)    576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 7, 7, 192)    576         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 7, 7, 192)    576         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 7, 7, 192)    576         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 7, 7, 192)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 192)    0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 192)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 192)    0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_285[0][0]             \n",
      "                                                                 activation_288[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 7, 7, 160)    480         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 7, 7, 160)    0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 7, 7, 160)    179200      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 7, 7, 160)    480         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 7, 7, 160)    0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 7, 7, 160)    179200      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 7, 7, 160)    480         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 7, 7, 160)    480         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 7, 7, 160)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 7, 7, 160)    0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 7, 7, 160)    179200      activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 7, 7, 160)    179200      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 7, 7, 160)    480         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 7, 7, 160)    480         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 7, 7, 160)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 7, 7, 160)    0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 7, 7, 192)    215040      activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 7, 7, 192)    215040      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 7, 7, 192)    576         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 7, 7, 192)    576         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 7, 7, 192)    576         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 7, 7, 192)    576         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 7, 7, 192)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 7, 7, 192)    0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 7, 7, 192)    0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 7, 7, 192)    0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_295[0][0]             \n",
      "                                                                 activation_298[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 7, 7, 160)    480         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 7, 7, 160)    0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 7, 7, 160)    179200      activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 7, 7, 160)    480         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 7, 7, 160)    0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 7, 7, 160)    179200      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 7, 7, 160)    480         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 7, 7, 160)    480         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 7, 7, 160)    0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 7, 7, 160)    0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 7, 7, 160)    179200      activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 7, 7, 160)    179200      activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 7, 7, 160)    480         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 7, 7, 160)    480         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 7, 7, 160)    0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 7, 7, 160)    0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 7, 7, 192)    215040      activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 7, 7, 192)    215040      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 7, 7, 192)    576         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 7, 7, 192)    576         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 7, 7, 192)    576         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 7, 7, 192)    576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 7, 7, 192)    0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 7, 7, 192)    0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 7, 7, 192)    0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 7, 7, 192)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_305[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "                                                                 activation_313[0][0]             \n",
      "                                                                 activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 7, 7, 192)    576         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 7, 7, 192)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 7, 7, 192)    258048      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 7, 7, 192)    576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 7, 7, 192)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 7, 7, 192)    258048      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 7, 7, 192)    576         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 7, 7, 192)    576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 7, 7, 192)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 7, 7, 192)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 7, 7, 192)    258048      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 7, 7, 192)    258048      activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 7, 7, 192)    576         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 7, 7, 192)    576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 7, 7, 192)    0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 7, 7, 192)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 7, 7, 192)    258048      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 7, 7, 192)    258048      activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 7, 7, 192)    576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 7, 7, 192)    576         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 7, 7, 192)    576         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 7, 7, 192)    576         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 7, 7, 192)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 7, 7, 192)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 7, 7, 192)    0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 7, 7, 192)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_315[0][0]             \n",
      "                                                                 activation_318[0][0]             \n",
      "                                                                 activation_323[0][0]             \n",
      "                                                                 activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024,activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1,activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir,'horses')\n",
    "train_humans_dir = os.path.join(train_dir,'humans')\n",
    "validation_horses_dir = os.path.join(validation_dir,'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir,'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 - 38s - loss: 0.2523 - acc: 0.8909 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "52/52 - 37s - loss: 0.1388 - acc: 0.9445 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 - 36s - loss: 0.0697 - acc: 0.9718 - val_loss: 0.0043 - val_acc: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 52,\n",
    "            epochs = 3,\n",
    "            validation_steps = 13,\n",
    "            verbose = 2,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
